{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf594f6-7c14-42bc-ae6b-73093770a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "from functools import partial\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "\n",
    "from transformers import AdamW, T5Tokenizer\n",
    "from mvp.t5 import MyT5ForConditionalGeneration\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from mvp.data_utils import *\n",
    "from mvp.eval_utils import *\n",
    "from mvp.process import *\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "875ff26f-a3af-47e6-982f-ae79f03a860c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method: mvp\n",
      "output path: /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n"
     ]
    }
   ],
   "source": [
    "# setting args\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.path = '/home/elicer/ABSA'\n",
    "        self.data_path = f'{self.path}/data'\n",
    "        self.method = 'mvp' # task \n",
    "        self.paraphrase = False # task \n",
    "        self.task = 'asqp' # task \n",
    "        self.dataset = 'rest16' # data \n",
    "        self.eval_data_split = 'test' # test or dev\n",
    "        self.top_k = 5\n",
    "        self.ctrl_token = \"post\"\n",
    "        self.data_ratio = 1.0\n",
    "        self.model_name_or_path = 't5-base' # used base model\n",
    "        self.load_ckpt_name = None # 사전 훈련된 모델의 체크포인트 파일로드 \n",
    "        self.do_train = False # train or not\n",
    "        self.do_inference = True # inference or not\n",
    "        self.max_seq_length = 200 # 입력 시퀀스 최대 길이\n",
    "        self.n_gpu = 1 # gpu 개수\n",
    "        self.train_batch_size = 16\n",
    "        self.eval_batch_size = 64\n",
    "        self.gradient_accumulation_steps = 1\n",
    "        self.learning_rate = 1e-4\n",
    "        self.num_train_epochs = 20\n",
    "        self.seed = 25\n",
    "        self.weight_decay = 0.0\n",
    "        self.adam_epsilon = 1e-8\n",
    "        self.warmup_steps = 0.0\n",
    "        self.multi_path = False\n",
    "        self.num_path = 1\n",
    "        self.beam_size = 1\n",
    "        self.save_top_k = 1\n",
    "        self.check_val_every_n_epoch = 10\n",
    "        self.single_view_type = \"rank\"\n",
    "        self.sort_label = False\n",
    "        self.load_path_cache = False\n",
    "        self.lowercase = False\n",
    "        self.multi_task = False\n",
    "        self.constrained_decode = False\n",
    "        self.agg_strategy = 'vote'\n",
    "\n",
    "def init_args():\n",
    "    args = Args()\n",
    "\n",
    "    if args.task == 'asqp':\n",
    "        args.lowercase = True\n",
    "\n",
    "    if args.method == 'dlo':\n",
    "        args.top_k = 1\n",
    "        args.single_view_type = \"heuristic\"\n",
    "        args.agg_strategy = 'heuristic'\n",
    "\n",
    "    if args.method == 'paraphrase':\n",
    "        args.paraphrase = True\n",
    "        args.output_dir =  f'{args.path}/outputs/{args.method}/{args.task}/{args.dataset}/{args.ctrl_token}_data{args.data_ratio}'\n",
    "    else:\n",
    "        args.output_dir =  f'{args.path}/outputs/{args.method}/{args.task}/{args.dataset}/top_{args.top_k}_{args.ctrl_token}_data{args.data_ratio}'\n",
    "    \n",
    "    if not os.path.exists(args.output_dir):\n",
    "        #os.mkdir(args.output_dir)\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "    return args\n",
    "\n",
    "args = init_args()\n",
    "\n",
    "print('method:', args.method)\n",
    "print('output path:', args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16a43532-453c-48e7-91f5-290a4ec3b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Fine tune a pre-trained T5 model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, tfm_model, tokenizer):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['tfm_model'])\n",
    "        self.config = config\n",
    "        self.model = tfm_model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                attention_mask=None,\n",
    "                decoder_input_ids=None,\n",
    "                decoder_attention_mask=None,\n",
    "                labels=None):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(input_ids=batch[\"source_ids\"],\n",
    "                       attention_mask=batch[\"source_mask\"],\n",
    "                       labels=lm_labels,\n",
    "                       decoder_attention_mask=batch['target_mask'])\n",
    "\n",
    "        loss = outputs[0]\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, batch, stage=None):\n",
    "        # get f1\n",
    "        outs = self.model.generate(input_ids=batch['source_ids'],\n",
    "                                   attention_mask=batch['source_mask'],\n",
    "                                   max_length=self.config.max_seq_length,\n",
    "                                   return_dict_in_generate=True,\n",
    "                                   output_scores=True,\n",
    "                                   num_beams=1)\n",
    "\n",
    "        dec = [\n",
    "            self.tokenizer.decode(ids, skip_special_tokens=True)\n",
    "            for ids in outs.sequences\n",
    "        ]\n",
    "        target = [\n",
    "            self.tokenizer.decode(ids, skip_special_tokens=True)\n",
    "            for ids in batch[\"target_ids\"]\n",
    "        ]\n",
    "        if args.paraphrase:\n",
    "            scores, _, _ = compute_scores(dec, target, args.paraphrase, verbose=False)\n",
    "        else:\n",
    "            scores, _, _ = compute_scores(dec, target, args.paraphrase, verbose=False)\n",
    "        f1 = torch.tensor(scores['f1'], dtype=torch.float64)\n",
    "\n",
    "        # get loss\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f\"{stage}_loss\",\n",
    "                     loss,\n",
    "                     prog_bar=True,\n",
    "                     on_step=False,\n",
    "                     on_epoch=True)\n",
    "            self.log(f\"{stage}_f1\",\n",
    "                     f1,\n",
    "                     prog_bar=True,\n",
    "                     on_step=False,\n",
    "                     on_epoch=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\" Prepare optimizer and schedule (linear warmup and decay) \"\"\"\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in model.named_parameters()\n",
    "                    if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                self.config.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in model.named_parameters()\n",
    "                    if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.config.learning_rate,\n",
    "                          eps=self.config.adam_epsilon)\n",
    "        scheduler = {\n",
    "            \"scheduler\":\n",
    "            get_linear_schedule_with_warmup(optimizer,\n",
    "                                            **self.config.lr_scheduler_init),\n",
    "            \"interval\":\n",
    "            \"step\",\n",
    "        }\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        print(\"load training data.\")\n",
    "        train_dataset = ABSADataset(tokenizer=self.tokenizer,\n",
    "                                    task_name=args.task,\n",
    "                                    data_name=args.dataset,\n",
    "                                    data_type=\"train\",\n",
    "                                    top_k=self.config.top_k,\n",
    "                                    args=self.config,\n",
    "                                    max_len=self.config.max_seq_length)\n",
    "\n",
    "        dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.train_batch_size,\n",
    "            drop_last=True\n",
    "            if args.data_ratio > 0.3 else False, # don't drop on few-shot\n",
    "            shuffle=True,\n",
    "            num_workers=2)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = ABSADataset(tokenizer=self.tokenizer,\n",
    "                                  task_name=args.task,\n",
    "                                  data_name=args.dataset,\n",
    "                                  data_type=\"dev\",\n",
    "                                  top_k=self.config.num_path,\n",
    "                                  args=self.config,\n",
    "                                  max_len=self.config.max_seq_length)\n",
    "        return DataLoader(val_dataset,\n",
    "                          batch_size=self.config.eval_batch_size,\n",
    "                          num_workers=2)\n",
    "\n",
    "    @staticmethod\n",
    "    def rindex(_list, _value):\n",
    "        return len(_list) - _list[::-1].index(_value) - 1\n",
    "\n",
    "    def prefix_allowed_tokens_fn(self, task, data_name, source_ids, batch_id,\n",
    "                                 input_ids):\n",
    "        \"\"\"\n",
    "        Constrained Decoding\n",
    "        # ids = self.tokenizer(\"text\", return_tensors='pt')['input_ids'].tolist()[0]\n",
    "        \"\"\"\n",
    "        if not os.path.exists('./force_tokens.json'):\n",
    "            dic = {\"cate_tokens\":{}, \"all_tokens\":{}, \"sentiment_tokens\":[], 'special_tokens':[]}\n",
    "            for task in force_words.keys():\n",
    "                dic[\"all_tokens\"][task] = {}\n",
    "                for dataset in force_words[task].keys():\n",
    "                    cur_list = force_words[task][dataset]\n",
    "                    tokenize_res = []\n",
    "                    for w in cur_list:\n",
    "                        tokenize_res.extend(self.tokenizer(w, return_tensors='pt')['input_ids'].tolist()[0])\n",
    "                    dic[\"all_tokens\"][task][dataset] = tokenize_res\n",
    "            for k,v in cate_list.items():\n",
    "                tokenize_res = []\n",
    "                for w in v:\n",
    "                    tokenize_res.extend(self.tokenizer(w, return_tensors='pt')['input_ids'].tolist()[0]) \n",
    "                dic[\"cate_tokens\"][k] = tokenize_res\n",
    "            sp_tokenize_res = []\n",
    "            for sp in ['great', 'ok', 'bad']:\n",
    "                sp_tokenize_res.extend(self.tokenizer(sp, return_tensors='pt')['input_ids'].tolist()[0])\n",
    "            for task in force_words.keys():\n",
    "                dic['sentiment_tokens'][task] = sp_tokenize_res\n",
    "            dic['sentiment_tokens'] = sp_tokenize_res\n",
    "            special_tokens_tokenize_res = []\n",
    "            for w in ['[O','[A','[S','[C','[SS']:\n",
    "                special_tokens_tokenize_res.extend(self.tokenizer(w, return_tensors='pt')['input_ids'].tolist()[0]) \n",
    "            special_tokens_tokenize_res = [r for r in special_tokens_tokenize_res if r != 784]\n",
    "            dic['special_tokens'] = special_tokens_tokenize_res\n",
    "            import json\n",
    "            with open(\"force_tokens.json\", 'w') as f:\n",
    "                json.dump(dic, f, indent=4)\n",
    "\n",
    "        to_id = {\n",
    "            'OT': [667],\n",
    "            'AT': [188],\n",
    "            'SP': [134],\n",
    "            'AC': [254],\n",
    "            'SS': [4256],\n",
    "            'EP': [8569],\n",
    "            '[': [784],\n",
    "            ']': [908],\n",
    "            'it': [34],\n",
    "            'null': [206,195]\n",
    "        }\n",
    "\n",
    "        left_brace_index = (input_ids == to_id['['][0]).nonzero()\n",
    "        right_brace_index = (input_ids == to_id[']'][0]).nonzero()\n",
    "        num_left_brace = len(left_brace_index)\n",
    "        num_right_brace = len(right_brace_index)\n",
    "        last_right_brace_pos = right_brace_index[-1][\n",
    "            0] if right_brace_index.nelement() > 0 else -1\n",
    "        last_left_brace_pos = left_brace_index[-1][\n",
    "            0] if left_brace_index.nelement() > 0 else -1\n",
    "        cur_id = input_ids[-1]\n",
    "\n",
    "        if cur_id in to_id['[']:\n",
    "            return force_tokens['special_tokens']\n",
    "        elif cur_id in to_id['AT'] + to_id['OT'] + to_id['EP'] + to_id['SP'] + to_id['AC']:  \n",
    "            return to_id[']']  \n",
    "        elif cur_id in to_id['SS']:  \n",
    "            return to_id['EP'] \n",
    "\n",
    "        # get cur_term\n",
    "        if last_left_brace_pos == -1:\n",
    "            return to_id['['] + [1]   # start of sentence: [\n",
    "        elif (last_left_brace_pos != -1 and last_right_brace_pos == -1) \\\n",
    "            or last_left_brace_pos > last_right_brace_pos:\n",
    "            return to_id[']']  # ]\n",
    "        else:\n",
    "            cur_term = input_ids[last_left_brace_pos + 1]\n",
    "\n",
    "        ret = []\n",
    "        if cur_term in to_id['SP']:  # SP\n",
    "            ret = force_tokens['sentiment_tokens'][task]\n",
    "        elif cur_term in to_id['AT']:  # AT\n",
    "            force_list = source_ids[batch_id].tolist()\n",
    "            if task != 'aste':  \n",
    "                force_list.extend(to_id['it'] + [1])  \n",
    "            ret = force_list  \n",
    "        elif cur_term in to_id['SS']:\n",
    "            ret = [3] + to_id[']'] + [1]\n",
    "        elif cur_term in to_id['AC']:  # AC\n",
    "            ret = force_tokens['cate_tokens'][data_name]\n",
    "        elif cur_term in to_id['OT']:  # OT\n",
    "            force_list = source_ids[batch_id].tolist()\n",
    "            if task == \"acos\":\n",
    "                force_list.extend(to_id['null'])  # null\n",
    "            ret = force_list\n",
    "        else:\n",
    "            raise ValueError(cur_term)\n",
    "\n",
    "        if num_left_brace == num_right_brace:\n",
    "            ret = set(ret)\n",
    "            ret.discard(to_id[']'][0]) # remove ]\n",
    "            for w in force_tokens['special_tokens']:\n",
    "                ret.discard(w)\n",
    "            ret = list(ret)\n",
    "        elif num_left_brace > num_right_brace:\n",
    "            ret += to_id[']'] \n",
    "        else:\n",
    "            raise ValueError\n",
    "        ret.extend(to_id['['] + [1]) # add [\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106a7f84-fefc-4f18-9c33-bd885a25617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 723\n",
      "Total examples = 723\n",
      "723 723 723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:10<00:00,  5.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 452, 2: 182, 3: 72, 4: 15, 5: 1, 6: 1})\n",
      "gold  [O] not any longer [A] place [C] restaurant general [S] bad\n",
      "pred  [O] good [A] place [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] null [A] it [C] service general [S] bad\n",
      "pred  [O] never brought us complimentary noodles [A] noodles [C] food quality [S] bad [SSEP] [O] ignored repeated requests for sugar [A] it [C] service general [S] bad\n",
      "\n",
      "gold  [O] outrageously good [A] food [C] food quality [S] great\n",
      "pred  [O] good [A] food [C] food quality [S] great\n",
      "\n",
      "gold  [O] well [A] it [C] restaurant prices [S] great [SSEP] [O] well [A] it [C] food quality [S] great\n",
      "pred  [O] can not eat this well [A] it [C] food quality [S] bad [SSEP] [O] well [A] it [C] food prices [S] bad\n",
      "\n",
      "gold  [O] null [A] cart attendant [C] service general [S] bad\n",
      "pred  [O] walked away [A] cart attendant [C] service general [S] bad\n",
      "\n",
      "gold  [O] null [A] it [C] service general [S] bad\n",
      "pred  [O] asked her three times [A] it [C] service general [S] bad\n",
      "\n",
      "gold  [O] great [A] fish [C] restaurant general [S] great [SSEP] [O] glad [A] it [C] restaurant general [S] great\n",
      "pred  [O] great [A] place [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] devine [A] service [C] service general [S] great [SSEP] [O] sensual [A] oysters [C] food quality [S] great [SSEP] [O] null [A] it [C] restaurant prices [S] great\n",
      "pred  [O] devine [A] service [C] service general [S] great [SSEP] [O] sensual [A] oysters [C] food quality [S] great [SSEP] [O] can't be beat [A] it [C] restaurant prices [S] great\n",
      "\n",
      "gold  [O] null [A] it [C] restaurant general [S] great\n",
      "pred  [O] go wrong [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] null [A] restaurant saul [C] restaurant general [S] great\n",
      "pred  [O] make it a point [A] restaurant saul [C] restaurant general [S] great\n",
      "\n",
      "number of gold spans: 1259, predicted spans: 1103, hit: 399\n",
      "\n",
      "zero_train_acos_rest16_1 vote precision: 36.17 recall: 31.69 F1 = 33.78\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 723\n",
      "Total examples = 723\n",
      "723 723 723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:08<00:00,  5.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 494, 2: 161, 3: 56, 4: 12})\n",
      "gold  [O] not any longer [A] place [C] restaurant general [S] bad\n",
      "pred  [O] good [A] place [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] null [A] it [C] service general [S] bad\n",
      "pred  [O] threw our dishes on the table [A] it [C] service general [S] bad\n",
      "\n",
      "gold  [O] outrageously good [A] food [C] food quality [S] great\n",
      "pred  [O] good [A] food [C] food quality [S] great\n",
      "\n",
      "gold  [O] well [A] it [C] restaurant prices [S] great [SSEP] [O] well [A] it [C] food quality [S] great\n",
      "pred  [O] can not eat this well [A] it [C] food quality [S] bad [SSEP] [O] well [A] it [C] food prices [S] bad\n",
      "\n",
      "gold  [O] null [A] cart attendant [C] service general [S] bad\n",
      "pred  [O] walked away [A] cart attendant [C] service general [S] bad\n",
      "\n",
      "gold  [O] null [A] it [C] service general [S] bad\n",
      "pred  [O] asked her three times [A] it [C] service general [S] bad\n",
      "\n",
      "gold  [O] great [A] fish [C] restaurant general [S] great [SSEP] [O] glad [A] it [C] restaurant general [S] great\n",
      "pred  [O] great [A] place [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] devine [A] service [C] service general [S] great [SSEP] [O] sensual [A] oysters [C] food quality [S] great [SSEP] [O] null [A] it [C] restaurant prices [S] great\n",
      "pred  [O] devine [A] service [C] service general [S] great [SSEP] [O] sensual [A] oysters [C] food quality [S] great [SSEP] [O] can't be beat [A] it [C] restaurant prices [S] great\n",
      "\n",
      "gold  [O] null [A] it [C] restaurant general [S] great\n",
      "pred  [O] go wrong [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] null [A] restaurant saul [C] restaurant general [S] great\n",
      "pred  [O] make it a point [A] restaurant saul [C] restaurant general [S] great\n",
      "\n",
      "number of gold spans: 1259, predicted spans: 1032, hit: 347\n",
      "\n",
      "zero_train_acos_rest16_2 vote precision: 33.62 recall: 27.56 F1 = 30.29\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 723\n",
      "Total examples = 723\n",
      "723 723 723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:12<00:00,  6.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 447, 2: 180, 3: 78, 4: 14, 5: 3, 6: 1})\n",
      "gold  [O] not any longer [A] place [C] restaurant general [S] bad\n",
      "pred  [O] good [A] place [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] null [A] it [C] service general [S] bad\n",
      "pred  [O] never brought us complimentary noodles [A] noodles [C] food quality [S] bad [SSEP] [O] ignored repeated requests for sugar [A] it [C] service general [S] bad\n",
      "\n",
      "gold  [O] outrageously good [A] food [C] food quality [S] great\n",
      "pred  [O] good [A] food [C] food quality [S] great\n",
      "\n",
      "gold  [O] well [A] it [C] restaurant prices [S] great [SSEP] [O] well [A] it [C] food quality [S] great\n",
      "pred  [O] can not eat this well [A] it [C] food quality [S] bad [SSEP] [O] well [A] it [C] food prices [S] bad\n",
      "\n",
      "gold  [O] null [A] cart attendant [C] service general [S] bad\n",
      "pred  [O] walked away [A] cart attendant [C] service general [S] bad\n",
      "\n",
      "gold  [O] null [A] it [C] service general [S] bad\n",
      "pred  [O] asked her three times [A] it [C] service general [S] bad\n",
      "\n",
      "gold  [O] great [A] fish [C] restaurant general [S] great [SSEP] [O] glad [A] it [C] restaurant general [S] great\n",
      "pred  [O] great [A] place [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] devine [A] service [C] service general [S] great [SSEP] [O] sensual [A] oysters [C] food quality [S] great [SSEP] [O] null [A] it [C] restaurant prices [S] great\n",
      "pred  [O] devine [A] service [C] service general [S] great [SSEP] [O] sensual [A] oysters [C] food quality [S] great [SSEP] [O] can't be beat [A] it [C] restaurant prices [S] great\n",
      "\n",
      "gold  [O] null [A] it [C] restaurant general [S] great\n",
      "pred  [O] go wrong [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] null [A] restaurant saul [C] restaurant general [S] great\n",
      "pred  [O] make it a point [A] restaurant saul [C] restaurant general [S] great\n",
      "\n",
      "number of gold spans: 1259, predicted spans: 1118, hit: 412\n",
      "\n",
      "zero_train_acos_rest16_3 vote precision: 36.85 recall: 32.72 F1 = 34.67\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 723\n",
      "Total examples = 723\n",
      "723 723 723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:11<00:00,  5.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 450, 2: 175, 3: 82, 4: 13, 5: 3})\n",
      "gold  [O] not any longer [A] place [C] restaurant general [S] bad\n",
      "pred  [O] good [A] place [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] null [A] it [C] service general [S] bad\n",
      "pred  [O] never brought us complimentary noodles [A] noodles [C] food quality [S] bad [SSEP] [O] ignored repeated requests for sugar [A] it [C] service general [S] bad\n",
      "\n",
      "gold  [O] outrageously good [A] food [C] food quality [S] great\n",
      "pred  [O] good [A] food [C] food quality [S] great\n",
      "\n",
      "gold  [O] well [A] it [C] restaurant prices [S] great [SSEP] [O] well [A] it [C] food quality [S] great\n",
      "pred  [O] can not eat this well [A] it [C] food quality [S] bad [SSEP] [O] well [A] it [C] food prices [S] bad\n",
      "\n",
      "gold  [O] null [A] cart attendant [C] service general [S] bad\n",
      "pred  [O] walked away [A] cart attendant [C] service general [S] bad\n",
      "\n",
      "gold  [O] null [A] it [C] service general [S] bad\n",
      "pred  [O] came back [A] dish [C] food quality [S] great\n",
      "\n",
      "gold  [O] great [A] fish [C] restaurant general [S] great [SSEP] [O] glad [A] it [C] restaurant general [S] great\n",
      "pred  [O] great [A] place [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] devine [A] service [C] service general [S] great [SSEP] [O] sensual [A] oysters [C] food quality [S] great [SSEP] [O] null [A] it [C] restaurant prices [S] great\n",
      "pred  [O] devine [A] service [C] service general [S] great [SSEP] [O] sensual [A] oysters [C] food quality [S] great [SSEP] [O] can't be beat [A] it [C] restaurant prices [S] great\n",
      "\n",
      "gold  [O] null [A] it [C] restaurant general [S] great\n",
      "pred  [O] go wrong [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] null [A] restaurant saul [C] restaurant general [S] great\n",
      "pred  [O] make it a point [A] restaurant saul [C] restaurant general [S] great\n",
      "\n",
      "number of gold spans: 1259, predicted spans: 1113, hit: 403\n",
      "\n",
      "zero_train_acos_rest16_4 vote precision: 36.21 recall: 32.01 F1 = 33.98\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 723\n",
      "Total examples = 723\n",
      "723 723 723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:10<00:00,  5.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 438, 2: 183, 3: 87, 4: 13, 5: 2})\n",
      "gold  [O] not any longer [A] place [C] restaurant general [S] bad\n",
      "pred  [O] good [A] place [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] null [A] it [C] service general [S] bad\n",
      "pred  [O] never brought us complimentary noodles [A] noodles [C] food quality [S] bad [SSEP] [O] ignored repeated requests for sugar [A] it [C] service general [S] bad\n",
      "\n",
      "gold  [O] outrageously good [A] food [C] food quality [S] great\n",
      "pred  [O] good [A] food [C] food quality [S] great\n",
      "\n",
      "gold  [O] well [A] it [C] restaurant prices [S] great [SSEP] [O] well [A] it [C] food quality [S] great\n",
      "pred  [O] can not eat this well [A] it [C] food quality [S] bad [SSEP] [O] well [A] it [C] food prices [S] bad\n",
      "\n",
      "gold  [O] null [A] cart attendant [C] service general [S] bad\n",
      "pred  [O] walked away [A] cart attendant [C] service general [S] bad\n",
      "\n",
      "gold  [O] null [A] it [C] service general [S] bad\n",
      "pred  [O] asked her three times [A] it [C] service general [S] bad\n",
      "\n",
      "gold  [O] great [A] fish [C] restaurant general [S] great [SSEP] [O] glad [A] it [C] restaurant general [S] great\n",
      "pred  [O] great [A] place [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] devine [A] service [C] service general [S] great [SSEP] [O] sensual [A] oysters [C] food quality [S] great [SSEP] [O] null [A] it [C] restaurant prices [S] great\n",
      "pred  [O] devine [A] service [C] service general [S] great [SSEP] [O] sensual [A] oysters [C] food quality [S] great [SSEP] [O] can't be beat [A] it [C] restaurant prices [S] great\n",
      "\n",
      "gold  [O] null [A] it [C] restaurant general [S] great\n",
      "pred  [O] go wrong [A] it [C] restaurant general [S] great\n",
      "\n",
      "gold  [O] null [A] restaurant saul [C] restaurant general [S] great\n",
      "pred  [O] make it a point [A] restaurant saul [C] restaurant general [S] great\n",
      "\n",
      "number of gold spans: 1259, predicted spans: 1127, hit: 418\n",
      "\n",
      "zero_train_acos_rest16_5 vote precision: 37.09 recall: 33.20 F1 = 35.04\n",
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest16/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 723\n",
      "Total examples = 723\n",
      "723 723 723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [00:40<00:40,  6.72s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m     f\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m                      \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                      \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_data_split\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     exp_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m precision: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m recall: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m F1 = \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     61\u001b[0m         args\u001b[38;5;241m.\u001b[39meval_data_split, args\u001b[38;5;241m.\u001b[39magg_strategy, scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m], scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m], scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/ABSA/src/mvp/eval_utils.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(args, model, task, data, data_type)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(data_loader):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# beam search\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     outs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    227\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m    228\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m             batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mconstrained_decode \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    237\u001b[0m     )\n\u001b[0;32m--> 239\u001b[0m     dec \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    240\u001b[0m         model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ids \u001b[38;5;129;01min\u001b[39;00m outs\u001b[38;5;241m.\u001b[39msequences\n\u001b[1;32m    242\u001b[0m     ]\n\u001b[1;32m    243\u001b[0m     target \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    244\u001b[0m         model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ids \u001b[38;5;129;01min\u001b[39;00m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    246\u001b[0m     ]\n\u001b[1;32m    247\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mextend(dec)\n",
      "File \u001b[0;32m~/ABSA/src/mvp/eval_utils.py:240\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(data_loader):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# beam search\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     outs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    227\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m    228\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m             batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mconstrained_decode \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    237\u001b[0m     )\n\u001b[1;32m    239\u001b[0m     dec \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 240\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ids \u001b[38;5;129;01min\u001b[39;00m outs\u001b[38;5;241m.\u001b[39msequences\n\u001b[1;32m    242\u001b[0m     ]\n\u001b[1;32m    243\u001b[0m     target \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    244\u001b[0m         model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ids \u001b[38;5;129;01min\u001b[39;00m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    246\u001b[0m     ]\n\u001b[1;32m    247\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mextend(dec)\n",
      "File \u001b[0;32m~/anaconda3/envs/mvp_seo/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3229\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3226\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3227\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3233\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3234\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mvp_seo/lib/python3.8/site-packages/transformers/tokenization_utils.py:914\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decode\u001b[39m(\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    906\u001b[0m     token_ids: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    911\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode_use_source_tokenizer \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_source_tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 914\u001b[0m     filtered_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_ids_to_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;66;03m# To avoid mixing byte-level and unicode for byte-level BPT\u001b[39;00m\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# we need to build string separately for added tokens and byte-level tokens\u001b[39;00m\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;66;03m# cf. https://github.com/huggingface/transformers/issues/1133\u001b[39;00m\n\u001b[1;32m    919\u001b[0m     sub_texts \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/mvp_seo/lib/python3.8/site-packages/transformers/tokenization_utils.py:890\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.convert_ids_to_tokens\u001b[0;34m(self, ids, skip_special_tokens)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m ids:\n\u001b[1;32m    889\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index)\n\u001b[0;32m--> 890\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m skip_special_tokens \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_ids\u001b[49m:\n\u001b[1;32m    891\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madded_tokens_decoder:\n",
      "File \u001b[0;32m~/anaconda3/envs/mvp_seo/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1258\u001b[0m, in \u001b[0;36mSpecialTokensMixin.all_special_ids\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;124;03m:obj:`List[int]`: List the ids of the special tokens(:obj:`'<unk>'`, :obj:`'<cls>'`, etc.) mapped to class\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;124;03mattributes.\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m all_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_special_tokens\n\u001b[0;32m-> 1258\u001b[0m all_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_tokens_to_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_toks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_ids\n",
      "File \u001b[0;32m~/anaconda3/envs/mvp_seo/lib/python3.8/site-packages/transformers/tokenization_utils.py:564\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.convert_tokens_to_ids\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    562\u001b[0m ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[0;32m--> 564\u001b[0m     ids\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_token_to_id_with_added_voc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "File \u001b[0;32m~/anaconda3/envs/mvp_seo/lib/python3.8/site-packages/transformers/tokenization_utils.py:573\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._convert_token_to_id_with_added_voc\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madded_tokens_encoder:\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madded_tokens_encoder[token]\n\u001b[0;32m--> 573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_token_to_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mvp_seo/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:267\u001b[0m, in \u001b[0;36mT5Tokenizer._convert_token_to_id\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts a token (str) in an id using the vocab.\"\"\"\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<extra_id_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 267\u001b[0m     match \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<extra_id_(\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md+)>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m-\u001b[39m num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/mvp_seo/lib/python3.8/re.py:191\u001b[0m, in \u001b[0;36mmatch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Try to apply the pattern at the start of the string, returning\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "\n",
    "    args.eval_data_split = f'train_zero_{i}'\n",
    "    print(\"\\n****** Conduct inference on trained checkpoint ******\")\n",
    "    \n",
    "    # initialize the T5 model from previous checkpoint\n",
    "    print(f\"Load trained model from {args.output_dir}\")\n",
    "    print(\n",
    "        'Note that a pretrained model is required and `do_true` should be False'\n",
    "    )\n",
    "\n",
    "    if args.task == 'asqp' and args.dataset == 'rest16':\n",
    "        model_path = os.path.join(args.output_dir, \"final2\")\n",
    "    else:\n",
    "        model_path = os.path.join(args.output_dir, \"final\")\n",
    "\n",
    "    if args.paraphrase:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(args.model_name_or_path, local_files_only=True if args.model_name_or_path != \"t5-base\" else False)\n",
    "    else:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "    tfm_model = MyT5ForConditionalGeneration.from_pretrained(model_path)\n",
    "    model = T5FineTuner(args, tfm_model, tokenizer)\n",
    "    \n",
    "    if args.load_ckpt_name:\n",
    "        ckpt_path = os.path.join(args.output_dir, args.load_ckpt_name)\n",
    "        print(\"Loading ckpt:\", ckpt_path)\n",
    "        checkpoint = torch.load(ckpt_path)\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    \n",
    "    log_file_path = os.path.join(args.output_dir, \"result.txt\")\n",
    "    \n",
    "    # compute the performance scores\n",
    "    with open(log_file_path, \"a+\") as f:\n",
    "        config_str = f\"seed: {args.seed}, beam: {args.beam_size}, constrained: {args.constrained_decode}\\n\"\n",
    "        print(config_str)\n",
    "        f.write(config_str)\n",
    "    \n",
    "        if args.multi_task:\n",
    "            f1s = []\n",
    "            for task in task_data_list:\n",
    "                for data in task_data_list[task]:\n",
    "                    scores = evaluate(model, task, data, data_type=args.eval_data_split)\n",
    "                    print(task, data, scores)\n",
    "                    exp_results = \"{} {} precision: {:.2f} recall: {:.2f} F1 = {:.2f}\".format(\n",
    "                        args.eval_data_split, args.agg_strategy, scores['precision'], scores['recall'],\n",
    "                        scores['f1'])\n",
    "                    f.write(f\"{task}: \\t{data}: \\t{exp_results}\\n\")\n",
    "                    f.flush()\n",
    "                    f1s.append(scores['f1'])\n",
    "            f.write(f\"Average F1: \\t{sum(f1s) / len(f1s)}\\n\")\n",
    "            f.flush()\n",
    "        else:\n",
    "            scores = evaluate(args,\n",
    "                              model,\n",
    "                              args.task,\n",
    "                              args.dataset,\n",
    "                            data_type=args.eval_data_split)\n",
    "    \n",
    "            exp_results = \"{} {} precision: {:.2f} recall: {:.2f} F1 = {:.2f}\".format(\n",
    "                args.eval_data_split, args.agg_strategy, scores['precision'], scores['recall'], scores['f1'])\n",
    "            print()\n",
    "            print(exp_results)\n",
    "            f.write(exp_results + \"\\n\")\n",
    "            f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07876119-7e6f-4ca1-acc8-862bb1c2ab25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvp",
   "language": "python",
   "name": "mvp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

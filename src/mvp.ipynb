{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf594f6-7c14-42bc-ae6b-73093770a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "from functools import partial\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "\n",
    "from transformers import AdamW, T5Tokenizer\n",
    "from mvp.t5 import MyT5ForConditionalGeneration\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from mvp.data_utils import *\n",
    "from mvp.eval_utils import *\n",
    "from mvp.process import *\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875ff26f-a3af-47e6-982f-ae79f03a860c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method: mvp\n",
      "output path: /home/elicer/ABSA/outputs/mvp/asqp/rest15/top_5_post_data1.0\n"
     ]
    }
   ],
   "source": [
    "# setting args\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.path = '/home/elicer/ABSA'\n",
    "        self.data_path = f'{self.path}/data'\n",
    "        self.method = 'mvp' # task \n",
    "        self.paraphrase = False # task \n",
    "        self.task = 'asqp' # task \n",
    "        self.dataset = 'rest15' # data \n",
    "        self.eval_data_split = 'train-Copy1' # test or dev\n",
    "        self.top_k = 5\n",
    "        self.ctrl_token = \"post\"\n",
    "        self.data_ratio = 1.0\n",
    "        self.model_name_or_path = 't5-base' # used base model\n",
    "        self.load_ckpt_name = None # 사전 훈련된 모델의 체크포인트 파일로드 \n",
    "        self.do_train = False # train or not\n",
    "        self.do_inference = True # inference or not\n",
    "        self.max_seq_length = 512 # 입력 시퀀스 최대 길이\n",
    "        self.n_gpu = 1 # gpu 개수\n",
    "        self.train_batch_size = 16\n",
    "        self.eval_batch_size = 32\n",
    "        self.gradient_accumulation_steps = 1\n",
    "        self.learning_rate = 1e-4\n",
    "        self.num_train_epochs = 20\n",
    "        self.seed = 25\n",
    "        self.weight_decay = 0.0\n",
    "        self.adam_epsilon = 1e-8\n",
    "        self.warmup_steps = 0.0\n",
    "        self.multi_path = False\n",
    "        self.num_path = 1\n",
    "        self.beam_size = 1\n",
    "        self.save_top_k = 1\n",
    "        self.check_val_every_n_epoch = 10\n",
    "        self.single_view_type = \"rank\"\n",
    "        self.sort_label = False\n",
    "        self.load_path_cache = False\n",
    "        self.lowercase = False\n",
    "        self.multi_task = False\n",
    "        self.constrained_decode = False\n",
    "        self.agg_strategy = 'vote'\n",
    "\n",
    "def init_args():\n",
    "    args = Args()\n",
    "\n",
    "    if args.task == 'asqp':\n",
    "        args.lowercase = True\n",
    "\n",
    "    if args.method == 'dlo':\n",
    "        args.top_k = 1\n",
    "        args.single_view_type = \"heuristic\"\n",
    "        args.agg_strategy = 'heuristic'\n",
    "\n",
    "    if args.method == 'paraphrase':\n",
    "        args.paraphrase = True\n",
    "        args.output_dir =  f'{args.path}/outputs/{args.method}/{args.task}/{args.dataset}/{args.ctrl_token}_data{args.data_ratio}'\n",
    "    else:\n",
    "        args.output_dir =  f'{args.path}/outputs/{args.method}/{args.task}/{args.dataset}/top_{args.top_k}_{args.ctrl_token}_data{args.data_ratio}'\n",
    "    \n",
    "    if not os.path.exists(args.output_dir):\n",
    "        #os.mkdir(args.output_dir)\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "    return args\n",
    "\n",
    "args = init_args()\n",
    "\n",
    "print('method:', args.method)\n",
    "print('output path:', args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746c813a-884f-422f-ab48-621e58a3fd37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ============================== NEW EXP: asqp on rest15 ============================== \n",
      "\n",
      "Here is an example (from the dev set):\n",
      "Total examples = 834\n",
      "834 4170 4170\n"
     ]
    }
   ],
   "source": [
    "# mvp sample 수 확인  \n",
    "print(\"\\n\", \"=\" * 30, f\"NEW EXP: {args.task} on {args.dataset}\",\"=\" * 30, \"\\n\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(args.model_name_or_path, local_files_only=True if args.model_name_or_path != \"t5-base\" else False)\n",
    "# sanity check\n",
    "# show one sample to check the code and the expected output\n",
    "print(f\"Here is an example (from the dev set):\")\n",
    "dataset = ABSADataset(tokenizer=tokenizer,\n",
    "                  task_name=args.task,\n",
    "                  data_name=args.dataset,\n",
    "                  data_type='train',\n",
    "                  top_k=args.top_k,\n",
    "                  args=args,\n",
    "                  max_len=args.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a43532-453c-48e7-91f5-290a4ec3b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Fine tune a pre-trained T5 model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, tfm_model, tokenizer):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['tfm_model'])\n",
    "        self.config = config\n",
    "        self.model = tfm_model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                attention_mask=None,\n",
    "                decoder_input_ids=None,\n",
    "                decoder_attention_mask=None,\n",
    "                labels=None):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(input_ids=batch[\"source_ids\"],\n",
    "                       attention_mask=batch[\"source_mask\"],\n",
    "                       labels=lm_labels,\n",
    "                       decoder_attention_mask=batch['target_mask'])\n",
    "\n",
    "        loss = outputs[0]\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, batch, stage=None):\n",
    "        # get f1\n",
    "        outs = self.model.generate(input_ids=batch['source_ids'],\n",
    "                                   attention_mask=batch['source_mask'],\n",
    "                                   max_length=self.config.max_seq_length,\n",
    "                                   return_dict_in_generate=True,\n",
    "                                   output_scores=True,\n",
    "                                   num_beams=1)\n",
    "\n",
    "        dec = [\n",
    "            self.tokenizer.decode(ids, skip_special_tokens=True)\n",
    "            for ids in outs.sequences\n",
    "        ]\n",
    "        target = [\n",
    "            self.tokenizer.decode(ids, skip_special_tokens=True)\n",
    "            for ids in batch[\"target_ids\"]\n",
    "        ]\n",
    "        if args.paraphrase:\n",
    "            scores, _, _ = compute_scores(dec, target, args.paraphrase, verbose=False)\n",
    "        else:\n",
    "            scores, _, _ = compute_scores(dec, target, args.paraphrase, verbose=False)\n",
    "        f1 = torch.tensor(scores['f1'], dtype=torch.float64)\n",
    "\n",
    "        # get loss\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f\"{stage}_loss\",\n",
    "                     loss,\n",
    "                     prog_bar=True,\n",
    "                     on_step=False,\n",
    "                     on_epoch=True)\n",
    "            self.log(f\"{stage}_f1\",\n",
    "                     f1,\n",
    "                     prog_bar=True,\n",
    "                     on_step=False,\n",
    "                     on_epoch=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\" Prepare optimizer and schedule (linear warmup and decay) \"\"\"\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in model.named_parameters()\n",
    "                    if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                self.config.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in model.named_parameters()\n",
    "                    if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.config.learning_rate,\n",
    "                          eps=self.config.adam_epsilon)\n",
    "        scheduler = {\n",
    "            \"scheduler\":\n",
    "            get_linear_schedule_with_warmup(optimizer,\n",
    "                                            **self.config.lr_scheduler_init),\n",
    "            \"interval\":\n",
    "            \"step\",\n",
    "        }\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        print(\"load training data.\")\n",
    "        train_dataset = ABSADataset(tokenizer=self.tokenizer,\n",
    "                                    task_name=args.task,\n",
    "                                    data_name=args.dataset,\n",
    "                                    data_type=\"train\",\n",
    "                                    top_k=self.config.top_k,\n",
    "                                    args=self.config,\n",
    "                                    max_len=self.config.max_seq_length)\n",
    "\n",
    "        dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.train_batch_size,\n",
    "            drop_last=True\n",
    "            if args.data_ratio > 0.3 else False, # don't drop on few-shot\n",
    "            shuffle=True,\n",
    "            num_workers=2)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = ABSADataset(tokenizer=self.tokenizer,\n",
    "                                  task_name=args.task,\n",
    "                                  data_name=args.dataset,\n",
    "                                  data_type=\"dev\",\n",
    "                                  top_k=self.config.num_path,\n",
    "                                  args=self.config,\n",
    "                                  max_len=self.config.max_seq_length)\n",
    "        return DataLoader(val_dataset,\n",
    "                          batch_size=self.config.eval_batch_size,\n",
    "                          num_workers=2)\n",
    "\n",
    "    @staticmethod\n",
    "    def rindex(_list, _value):\n",
    "        return len(_list) - _list[::-1].index(_value) - 1\n",
    "\n",
    "    def prefix_allowed_tokens_fn(self, task, data_name, source_ids, batch_id,\n",
    "                                 input_ids):\n",
    "        \"\"\"\n",
    "        Constrained Decoding\n",
    "        # ids = self.tokenizer(\"text\", return_tensors='pt')['input_ids'].tolist()[0]\n",
    "        \"\"\"\n",
    "        if not os.path.exists('./force_tokens.json'):\n",
    "            dic = {\"cate_tokens\":{}, \"all_tokens\":{}, \"sentiment_tokens\":[], 'special_tokens':[]}\n",
    "            for task in force_words.keys():\n",
    "                dic[\"all_tokens\"][task] = {}\n",
    "                for dataset in force_words[task].keys():\n",
    "                    cur_list = force_words[task][dataset]\n",
    "                    tokenize_res = []\n",
    "                    for w in cur_list:\n",
    "                        tokenize_res.extend(self.tokenizer(w, return_tensors='pt')['input_ids'].tolist()[0])\n",
    "                    dic[\"all_tokens\"][task][dataset] = tokenize_res\n",
    "            for k,v in cate_list.items():\n",
    "                tokenize_res = []\n",
    "                for w in v:\n",
    "                    tokenize_res.extend(self.tokenizer(w, return_tensors='pt')['input_ids'].tolist()[0]) \n",
    "                dic[\"cate_tokens\"][k] = tokenize_res\n",
    "            sp_tokenize_res = []\n",
    "            for sp in ['great', 'ok', 'bad']:\n",
    "                sp_tokenize_res.extend(self.tokenizer(sp, return_tensors='pt')['input_ids'].tolist()[0])\n",
    "            for task in force_words.keys():\n",
    "                dic['sentiment_tokens'][task] = sp_tokenize_res\n",
    "            dic['sentiment_tokens'] = sp_tokenize_res\n",
    "            special_tokens_tokenize_res = []\n",
    "            for w in ['[O','[A','[S','[C','[SS']:\n",
    "                special_tokens_tokenize_res.extend(self.tokenizer(w, return_tensors='pt')['input_ids'].tolist()[0]) \n",
    "            special_tokens_tokenize_res = [r for r in special_tokens_tokenize_res if r != 784]\n",
    "            dic['special_tokens'] = special_tokens_tokenize_res\n",
    "            import json\n",
    "            with open(\"force_tokens.json\", 'w') as f:\n",
    "                json.dump(dic, f, indent=4)\n",
    "\n",
    "        to_id = {\n",
    "            'OT': [667],\n",
    "            'AT': [188],\n",
    "            'SP': [134],\n",
    "            'AC': [254],\n",
    "            'SS': [4256],\n",
    "            'EP': [8569],\n",
    "            '[': [784],\n",
    "            ']': [908],\n",
    "            'it': [34],\n",
    "            'null': [206,195]\n",
    "        }\n",
    "\n",
    "        left_brace_index = (input_ids == to_id['['][0]).nonzero()\n",
    "        right_brace_index = (input_ids == to_id[']'][0]).nonzero()\n",
    "        num_left_brace = len(left_brace_index)\n",
    "        num_right_brace = len(right_brace_index)\n",
    "        last_right_brace_pos = right_brace_index[-1][\n",
    "            0] if right_brace_index.nelement() > 0 else -1\n",
    "        last_left_brace_pos = left_brace_index[-1][\n",
    "            0] if left_brace_index.nelement() > 0 else -1\n",
    "        cur_id = input_ids[-1]\n",
    "\n",
    "        if cur_id in to_id['[']:\n",
    "            return force_tokens['special_tokens']\n",
    "        elif cur_id in to_id['AT'] + to_id['OT'] + to_id['EP'] + to_id['SP'] + to_id['AC']:  \n",
    "            return to_id[']']  \n",
    "        elif cur_id in to_id['SS']:  \n",
    "            return to_id['EP'] \n",
    "\n",
    "        # get cur_term\n",
    "        if last_left_brace_pos == -1:\n",
    "            return to_id['['] + [1]   # start of sentence: [\n",
    "        elif (last_left_brace_pos != -1 and last_right_brace_pos == -1) \\\n",
    "            or last_left_brace_pos > last_right_brace_pos:\n",
    "            return to_id[']']  # ]\n",
    "        else:\n",
    "            cur_term = input_ids[last_left_brace_pos + 1]\n",
    "\n",
    "        ret = []\n",
    "        if cur_term in to_id['SP']:  # SP\n",
    "            ret = force_tokens['sentiment_tokens'][task]\n",
    "        elif cur_term in to_id['AT']:  # AT\n",
    "            force_list = source_ids[batch_id].tolist()\n",
    "            if task != 'aste':  \n",
    "                force_list.extend(to_id['it'] + [1])  \n",
    "            ret = force_list  \n",
    "        elif cur_term in to_id['SS']:\n",
    "            ret = [3] + to_id[']'] + [1]\n",
    "        elif cur_term in to_id['AC']:  # AC\n",
    "            ret = force_tokens['cate_tokens'][data_name]\n",
    "        elif cur_term in to_id['OT']:  # OT\n",
    "            force_list = source_ids[batch_id].tolist()\n",
    "            if task == \"acos\":\n",
    "                force_list.extend(to_id['null'])  # null\n",
    "            ret = force_list\n",
    "        else:\n",
    "            raise ValueError(cur_term)\n",
    "\n",
    "        if num_left_brace == num_right_brace:\n",
    "            ret = set(ret)\n",
    "            ret.discard(to_id[']'][0]) # remove ]\n",
    "            for w in force_tokens['special_tokens']:\n",
    "                ret.discard(w)\n",
    "            ret = list(ret)\n",
    "        elif num_left_brace > num_right_brace:\n",
    "            ret += to_id[']'] \n",
    "        else:\n",
    "            raise ValueError\n",
    "        ret.extend(to_id['['] + [1]) # add [\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5c21bc-7695-4c75-9182-7e93e96aaf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train\n",
    "if args.do_train:\n",
    "    # initialize the T5 model\n",
    "    tfm_model = MyT5ForConditionalGeneration.from_pretrained(\n",
    "        args.model_name_or_path, local_files_only=True if args.model_name_or_path != \"t5-base\" else False)\n",
    "    model = T5FineTuner(args, tfm_model, tokenizer)\n",
    "    \n",
    "    # load data\n",
    "    train_loader = model.train_dataloader()\n",
    "    \n",
    "    # config optimizer\n",
    "    t_total = ((len(train_loader.dataset) //\n",
    "                (args.train_batch_size * max(1, args.n_gpu))) //\n",
    "               args.gradient_accumulation_steps *\n",
    "               float(args.num_train_epochs))\n",
    "    \n",
    "    args.lr_scheduler_init = {\n",
    "        \"num_warmup_steps\": args.warmup_steps,\n",
    "        \"num_training_steps\": t_total\n",
    "    }\n",
    "    \n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=args.output_dir,\n",
    "        filename='{epoch}-{val_f1:.2f}-{val_loss:.2f}',\n",
    "        monitor='val_f1',\n",
    "        mode='max',\n",
    "        save_top_k=args.save_top_k,\n",
    "        save_last=False)\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_f1\",\n",
    "                                        min_delta=0.00,\n",
    "                                        patience=20,\n",
    "                                        verbose=True,\n",
    "                                        mode=\"max\")\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    \n",
    "    # prepare for trainer\n",
    "    train_params = dict(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        default_root_dir=args.output_dir,\n",
    "        accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "        gradient_clip_val=1.0,\n",
    "        max_epochs=args.num_train_epochs,\n",
    "        check_val_every_n_epoch=args.check_val_every_n_epoch,\n",
    "        callbacks=[\n",
    "            checkpoint_callback, early_stop_callback,\n",
    "            TQDMProgressBar(refresh_rate=10), lr_monitor\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(**train_params)\n",
    "    \n",
    "    trainer.fit(model)\n",
    "    \n",
    "    # save the final model\n",
    "    model.model.save_pretrained(os.path.join(args.output_dir, \"final2\"))\n",
    "    if args.paraphrase == False:\n",
    "        tokenizer.save_pretrained(os.path.join(args.output_dir, \"final2\"))\n",
    "    print(\"Finish training and saving the model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "106a7f84-fefc-4f18-9c33-bd885a25617c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Load trained model from /home/elicer/ABSA/outputs/mvp/asqp/rest15/top_5_post_data1.0\n",
      "Note that a pretrained model is required and `do_true` should be False\n",
      "seed: 25, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 4263\n",
      "Total examples = 4263\n",
      "4263 4263 4263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [12:57<00:00,  5.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 2892, 2: 887, 3: 348, 4: 113, 5: 21, 6: 1, 8: 1})\n",
      "gold  [A] service [O] great [S] great [C] service general [SSEP] [A] dinner [O] great quality [S] great [C] food quality\n",
      "pred  [A] quality [O] great [S] great [C] food quality [SSEP] [A] service [O] great [S] great [C] service general\n",
      "\n",
      "gold  [A] it [O] cozy [S] great [C] ambience general\n",
      "pred  [A] it [O] dark [S] great [C] ambience general [SSEP] [A] it [O] cozy [S] great [C] ambience general [SSEP] [A] jazz music [O] playing [S] great [C] ambience general\n",
      "\n",
      "gold  [A] indian chinese food [O] great [S] great [C] food quality\n",
      "pred  [A] indian chinese food [O] great [S] great [C] food quality\n",
      "\n",
      "gold  [A] location [O] expect [S] ok [C] restaurant prices [SSEP] [A] location [O] expect [S] ok [C] restaurant miscellaneous\n",
      "pred  [A] location [O] not what i would expect [S] bad [C] restaurant prices [SSEP] [A] location [O] prestige [S] bad [C] location general\n",
      "\n",
      "gold  [A] chinese restaurant [O] reliable [S] great [C] restaurant general\n",
      "pred  [A] chinese restaurant [O] reliable [S] great [C] restaurant general\n",
      "\n",
      "gold  [A] lobster knuckles [O] ok [S] ok [C] food style_options [SSEP] [A] lobster knuckles [O] tasteless [S] bad [C] food quality\n",
      "pred  [A] lobster knuckles ( special of the day ) [O] ok [S] ok [C] food quality [SSEP] [A] lobster knuckles [O] tasteless [S] bad [C] food quality\n",
      "\n",
      "gold  [A] menu [O] simple [S] ok [C] food style_options\n",
      "pred  [A] menu [O] simple [S] great [C] food style_options\n",
      "\n",
      "gold  [A] place [O] worst [S] bad [C] restaurant general\n",
      "pred  [A] place [O] worst [S] bad [C] restaurant general\n",
      "\n",
      "gold  [A] it [O] never got an explanation [S] bad [C] service general\n",
      "pred  [A] it [O] never got an explanation [S] bad [C] service general\n",
      "\n",
      "gold  [A] food [O] happy [S] great [C] food quality [SSEP] [A] grilled mahi mahi [O] drenched [S] bad [C] food quality [SSEP] [A] grilled mahi mahi [O] drenched [S] bad [C] food style_options\n",
      "pred  [A] food [O] happy [S] great [C] food quality [SSEP] [A] grilled mahi mahi [O] drenched in grapfruit juice [S] bad [C] food quality\n",
      "\n",
      "number of gold spans: 6365, predicted spans: 6281, hit: 949\n",
      "train-Copy1 vote precision: 15.11 recall: 14.91 F1 = 15.01\n"
     ]
    }
   ],
   "source": [
    "# do inference\n",
    "if args.do_inference:\n",
    "    print(\"\\n****** Conduct inference on trained checkpoint ******\")\n",
    "    \n",
    "    # initialize the T5 model from previous checkpoint\n",
    "    print(f\"Load trained model from {args.output_dir}\")\n",
    "    print(\n",
    "        'Note that a pretrained model is required and `do_true` should be False'\n",
    "    )\n",
    "    # if args.task == 'asqp' and args.dataset == 'rest16':\n",
    "    #     model_path = os.path.join(args.output_dir, \"final2\")\n",
    "    # else:\n",
    "    #     model_path = os.path.join(args.output_dir, \"final\")\n",
    "\n",
    "    model_path = os.path.join(args.output_dir, \"final\")\n",
    "\n",
    "    if args.paraphrase:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(args.model_name_or_path, local_files_only=True if args.model_name_or_path != \"t5-base\" else False)\n",
    "    else:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "    tfm_model = MyT5ForConditionalGeneration.from_pretrained(model_path)\n",
    "    model = T5FineTuner(args, tfm_model, tokenizer)\n",
    "    \n",
    "    if args.load_ckpt_name:\n",
    "        ckpt_path = os.path.join(args.output_dir, args.load_ckpt_name)\n",
    "        print(\"Loading ckpt:\", ckpt_path)\n",
    "        checkpoint = torch.load(ckpt_path)\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    \n",
    "    log_file_path = os.path.join(args.output_dir, \"result.txt\")\n",
    "    \n",
    "    # compute the performance scores\n",
    "    with open(log_file_path, \"a+\") as f:\n",
    "        config_str = f\"seed: {args.seed}, beam: {args.beam_size}, constrained: {args.constrained_decode}\\n\"\n",
    "        print(config_str)\n",
    "        f.write(config_str)\n",
    "    \n",
    "        if args.multi_task:\n",
    "            f1s = []\n",
    "            for task in task_data_list:\n",
    "                for data in task_data_list[task]:\n",
    "                    scores = evaluate(model, task, data, data_type=args.eval_data_split)\n",
    "                    print(task, data, scores)\n",
    "                    exp_results = \"{} {} precision: {:.2f} recall: {:.2f} F1 = {:.2f}\".format(\n",
    "                        args.eval_data_split, args.agg_strategy, scores['precision'], scores['recall'],\n",
    "                        scores['f1'])\n",
    "                    f.write(f\"{task}: \\t{data}: \\t{exp_results}\\n\")\n",
    "                    f.flush()\n",
    "                    f1s.append(scores['f1'])\n",
    "            f.write(f\"Average F1: \\t{sum(f1s) / len(f1s)}\\n\")\n",
    "            f.flush()\n",
    "        else:\n",
    "            scores = evaluate(args,\n",
    "                              model,\n",
    "                              args.task,\n",
    "                              args.dataset,\n",
    "                            data_type=args.eval_data_split)\n",
    "    \n",
    "            exp_results = \"{} {} precision: {:.2f} recall: {:.2f} F1 = {:.2f}\".format(\n",
    "                args.eval_data_split, args.agg_strategy, scores['precision'], scores['recall'], scores['f1'])\n",
    "            print(exp_results)\n",
    "            f.write(exp_results + \"\\n\")\n",
    "            f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34390f-a95f-4329-97f1-83b69c166dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd0439b-0d31-4d30-8e1c-36acaa2ce499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvp",
   "language": "python",
   "name": "mvp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

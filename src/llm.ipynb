{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b05cf6f-8fe4-49b8-91b0-692fe5c3d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from llm.process import *\n",
    "from llm.data_utils import *\n",
    "from llm.eval_utils import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68bda216-371b-4c98-8cc3-5e7eebfb66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        # dataset parameters\n",
    "        self.path = '/home/elicer/ABSA'\n",
    "        self.data_path = f'{self.path}/data'\n",
    "        self.model = 'llm'\n",
    "        self.version = 'gpt-4-1106-preview'\n",
    "        self.task = 'acos' # task \n",
    "        self.dataset = 'rest16' # data \n",
    "        self.prompt_type = \"10shot\"\n",
    "        self.do_inference = True\n",
    "        self.eval_data_split = 'test' # test or dev\n",
    "        self.temperature = 0 \n",
    "        self.max_seq_length = 200 \n",
    "        self.lowercase = True\n",
    "        self.single_view_type = 'rand'\n",
    "        self.seed = 25\n",
    "        self.sort_label = False\n",
    "        self.multi_task = False\n",
    "        self.ctrl_token = \"post\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "optim_orders = ['[A] [C] [O] [S]']\n",
    "top_order = optim_orders[0].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8cdd0db-45b7-4e78-90e8-71154f5cd4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data :  /home/elicer/ABSA/data/acos/rest16/test.txt\n",
      "Total examples = 583\n"
     ]
    }
   ],
   "source": [
    "# data import\n",
    "data_path = f'{args.data_path}/{args.task}/{args.dataset}/{args.eval_data_split}.txt'\n",
    "\n",
    "print(\"load data : \",data_path)\n",
    "_, _, inputs, golds = read_line_examples_from_file(\n",
    "        data_path, args.task, args.dataset, args.lowercase)\n",
    "\n",
    "new_inputs = []\n",
    "for input in inputs:\n",
    "    text = \" \".join(input)\n",
    "    new_inputs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "918e4e6d-825b-4b55-8146-46f56e04e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "\n",
    "for label in golds:\n",
    "    all_quad_sentences = []\n",
    "    for _tuple in label:\n",
    "        at, ac, sp, ao = get_task_tuple(_tuple, args.task)\n",
    "        element_dict = {\"[A]\": at, \"[C]\": ac, \"[O]\": ao, \"[S]\": sp}\n",
    "        element_list = []\n",
    "        for key in top_order:\n",
    "            element_list.append(\"{} {}\".format(key, element_dict[key]))\n",
    "        one_quad_sentence = \" \".join(element_list)\n",
    "        all_quad_sentences.append(one_quad_sentence)\n",
    "    target = ' [SSEP] '.join(all_quad_sentences)\n",
    "    targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d38146-6d8e-4bae-b569-536fa2a01346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/elicer/ABSA/outputs/llm/acos_rest16_10shot_result.txt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = f'{args.path}/outputs/{args.model}/{args.task}_{args.dataset}_{args.prompt_type}_result.txt'\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0932ebc-bef5-47d7-a142-5157b222b909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yum !'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24da34ba-ae7d-4822-9725-f6b7684da438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"According to the following sentiment elements definition: \\n\\n- The 'aspect term' refers to a specific feature, attribute, or aspect of a product or service that a user may express an opinion about, the aspect term might be 'null' for implicit aspect.\\n- The 'opinion term' refers to the sentiment or attitude expressed by a user towards a particular aspect or feature of a product or service, the aspect term might be 'null' for implicit opinion.\\n- The 'aspect category' refers to the category that aspect belongs to, and the available catgories includes: 'location general', 'food prices', 'food quality', 'food general', 'ambience general', 'service general', 'restaurant prices', 'drinks prices', 'restaurant miscellaneous', 'drinks quality', 'drinks style_options', 'restaurant general' and 'food style_options'.\\n- The 'sentiment polarity' refers to the degree of positivity, negativity or neutrality expressed in the opinion towards a particular aspect or feature of a product or service, and the available polarities inlcudes: 'positive', 'negative' and 'neutral'.\\n\\nExtract the sentiment elements from the text according to the defined categories and format them as [['aspect term', 'opinion term', 'aspect category', 'sentiment polarity'], ...]. Reply with the answer only.\"},\n",
       " {'role': 'user', 'content': 'but that is highly forgivable .'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"[['null', 'forgivable', 'restaurant miscellaneous', 'great']]\"},\n",
       " {'role': 'system', 'content': ''},\n",
       " {'role': 'user',\n",
       "  'content': 'i have to say that i am pleasantly suprised and i will most likely stop in again if i am in the neighborhood .'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"[['null', 'pleasantly suprised', 'restaurant general', 'great']]\"},\n",
       " {'role': 'system', 'content': ''},\n",
       " {'role': 'user',\n",
       "  'content': 'the signs , the specials menus , food , and even all the waitstaff are all totally japanese .'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"[['signs', 'japanese', 'restaurant miscellaneous', 'great'], ['specials menus', 'japanese', 'food style_options', 'great'], ['food', 'japanese', 'food quality', 'great'], ['waitstaff', 'japanese', 'service general', 'great']]\"},\n",
       " {'role': 'system', 'content': ''},\n",
       " {'role': 'user',\n",
       "  'content': 'i like cafe noir dont get me wrong , it is jsut that the people who work there are evil and incompetent ! !'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"[['cafe noir', 'like', 'restaurant general', 'great'], ['people', 'evil', 'service general', 'bad'], ['people', 'incompetent', 'service general', 'bad']]\"},\n",
       " {'role': 'system', 'content': ''},\n",
       " {'role': 'user',\n",
       "  'content': 'the waiter was attentive , the food was delicious and the views of the city were great .'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"[['waiter', 'attentive', 'service general', 'great'], ['food', 'delicious', 'food quality', 'great'], ['views of the city', 'great', 'location general', 'great']]\"},\n",
       " {'role': 'system', 'content': ''},\n",
       " {'role': 'user', 'content': 'i love it .'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"[['null', 'love', 'restaurant general', 'great']]\"},\n",
       " {'role': 'system', 'content': ''},\n",
       " {'role': 'user',\n",
       "  'content': 'a cool bar with great food , and tons of excellent beer .'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"[['bar', 'cool', 'ambience general', 'great'], ['food', 'great', 'food quality', 'great'], ['beer', 'excellent', 'drinks quality', 'great'], ['beer', 'excellent', 'drinks style_options', 'great']]\"},\n",
       " {'role': 'system', 'content': ''},\n",
       " {'role': 'user',\n",
       "  'content': \"guacamole + shrimp appetizer was really great , we both had the filet , very good , did n ' t much like the frites that came with , but the filet was so good , neither of us cared .\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"[['guacamole + shrimp appetizer', 'great', 'food quality', 'great'], ['filet', 'good', 'food quality', 'great'], ['frites', 'null', 'food quality', 'bad']]\"},\n",
       " {'role': 'system', 'content': ''},\n",
       " {'role': 'user',\n",
       "  'content': 'i have never before eaten 40 pieces of relatively good nigiri .'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"[['nigiri', 'good', 'food quality', 'ok']]\"},\n",
       " {'role': 'system', 'content': ''},\n",
       " {'role': 'user', 'content': 'the service was attentive , yet discreet .'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"[['service', 'attentive', 'service general', 'great'], ['service', 'discreet', 'service general', 'great']]\"},\n",
       " {'role': 'user', 'content': 'yum !'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_path = f'{args.path}/src/{args.model}'\n",
    "process_prompt(new_inputs[0], prompt_path, args.task, args.dataset, args.prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc34b20-de36-4134-a2f3-2685eadde2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing input at index 80: name 'null' is not defined\n",
      "Error processing input at index 106: name 'null' is not defined\n",
      "Error processing input at index 197: unexpected EOF while parsing (<string>, line 1)\n",
      "Error processing input at index 228: invalid syntax (<string>, line 1)\n",
      "[['null', 'prefer', 'restaurant general', 'positive'], ['servers', \"do n ' t like\", 'service general', 'negative'], ['one young woman', 'in particular', 'service general', 'negative']]\n",
      "Error processing input at index 326: invalid syntax (<string>, line 1)\n",
      "[['null', 'bravo', 'restaurant general', 'positive'], ['null', \"can't wait to come back\", 'restaurant general', 'positive']]\n",
      "Error processing input at index 426: invalid syntax (<string>, line 1)\n",
      "[['null', 'packaged everything nicely', 'restaurant general', 'positive'], ['null', \"did n ' t spill\", 'restaurant general', 'positive']]\n",
      "Error processing input at index 472: EOL while scanning string literal (<string>, line 1)\n",
      "Error processing input at index 493: invalid syntax (<string>, line 1)\n",
      "[['give away', \"does n ' t work\", 'restaurant miscellaneous', 'negative'], ['service', 'non existent', 'service general', 'negative']]\n",
      "Error processing input at index 496: invalid syntax (<string>, line 1)\n",
      "[['null', \"does n ' t work\", 'restaurant miscellaneous', 'negative']]\n",
      "Error processing input at index 498: invalid syntax (<string>, line 1)\n",
      "[['null', \"does n ' t make you feel welcome\", 'service general', 'negative'], ['null', 'treats you like an annoyance', 'service general', 'negative']]\n",
      "Error processing input at index 519: invalid syntax (<string>, line 1)\n",
      "[['bread service', \"do n ' t have\", 'restaurant miscellaneous', 'negative']]\n",
      "Error processing input at index 566: invalid syntax (<string>, line 1)\n",
      "[['null', \"would n ' t go back\", 'restaurant general', 'negative']]\n",
      "Error processing input at index 582: invalid syntax (<string>, line 1)\n",
      "[[\"Ray's Boathouse\", 'deserving', 'restaurant general', 'positive']]\n",
      "save inference file :  /home/elicer/ABSA/outputs/llm/acos_rest16_0shot_result.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# do inference\n",
    "if args.do_inference:\n",
    "    prompt_path = f'{args.path}/src/{args.model}'\n",
    "    \n",
    "    predicts = []\n",
    "    for index, input_item in enumerate(new_inputs):\n",
    "        try:\n",
    "            prompt = process_prompt(input_item, prompt_path, args.task, args.dataset, args.prompt_type)\n",
    "            target = llm_chat(prompt, args.version, args.temperature, args.max_seq_length)\n",
    "            if target == []:\n",
    "                predicts.append(None)\n",
    "            else: \n",
    "                predicts.append(eval(target))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing input at index {index}: {e}\")\n",
    "            if 'invalid syntax' in str(e) and target.startswith('['):\n",
    "                target = fix_string(target)\n",
    "                predicts.append(eval(target))\n",
    "                print(target)\n",
    "            else:\n",
    "                predicts.append(None)\n",
    "        # save inference result\n",
    "    predict_list = [repr(sublist) if sublist is not None else \"['null', 'null', 'null', 'null']\" for sublist in predicts]\n",
    "    merge_save(new_inputs, predict_list, output_path, 1)\n",
    "    print(\"save inference file : \",output_path)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaeff8e4-8d92-42a0-82f2-b6f9f8269cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data :  /home/elicer/ABSA/outputs/llm/acos_rest16_0shot_result.txt\n",
      "Total examples = 583\n"
     ]
    }
   ],
   "source": [
    "print(\"load data : \",output_path)\n",
    "_, _, inputs, predicts = read_line_examples_from_file(\n",
    "        output_path, args.task, args.dataset, args.lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b0511a-2d1f-4a53-9198-1813af824fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "for label in predicts:\n",
    "    all_quad_sentences = []\n",
    "    for _tuple in label:\n",
    "        at, ot, ac, sp = _tuple\n",
    "        if sp  == 'positive':\n",
    "            sp = 'great'\n",
    "        if sp  == 'negative':\n",
    "            sp = 'bad'\n",
    "        if sp  == 'neutral':\n",
    "            sp = 'ok'\n",
    "        element_dict = {\"[A]\": at, \"[C]\": ac, \"[O]\": ot, \"[S]\": sp}\n",
    "        element_list = []\n",
    "        for key in top_order:\n",
    "            element_list.append(\"{} {}\".format(key, element_dict[key]))\n",
    "        one_quad_sentence = \" \".join(element_list)\n",
    "        all_quad_sentences.append(one_quad_sentence)\n",
    "    target = ' [SSEP] '.join(all_quad_sentences)\n",
    "    outputs.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035a7c45-23c1-4ab7-adc4-a0b96080562d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 307, 2: 188, 3: 56, 4: 24, 5: 6, 7: 1, 9: 1})\n",
      "gold  [A] it [C] food quality [O] yum [S] great\n",
      "pred  [A] null [C] food general [O] yum [S] great\n",
      "\n",
      "gold  [A] sushi [C] food quality [O] good [S] great\n",
      "pred  [A] sushi [C] food quality [O] really good [S] great\n",
      "\n",
      "gold  [A] portions [C] food style_options [O] not the biggest [S] ok [SSEP] [A] portions [C] food style_options [O] adequate [S] ok\n",
      "pred  [A] portions [C] food general [O] not the biggest [S] bad [SSEP] [A] portions [C] food general [O] adequate [S] ok\n",
      "\n",
      "gold  [A] green tea creme brulee [C] food quality [O] must [S] great\n",
      "pred  [A] green tea creme brulee [C] food quality [O] a must [S] great\n",
      "\n",
      "gold  [A] sushi [C] food quality [O] great [S] great [SSEP] [A] service [C] service general [O] better [S] great\n",
      "pred  [A] sushi [C] food quality [O] great [S] great [SSEP] [A] service [C] service general [O] even better [S] great\n",
      "\n",
      "gold  [A] staff [C] service general [O] accomodating [S] great\n",
      "pred  [A] staff [C] service general [O] extremely accomodating [S] great [SSEP] [A] staff [C] service general [O] tended to my every need [S] great\n",
      "\n",
      "gold  [A] restaurant [C] restaurant general [O] no complaints [S] great\n",
      "pred  [A] null [C] restaurant general [O] no complaints [S] great\n",
      "\n",
      "gold  [A] owner [C] service general [O] belligerent [S] bad\n",
      "pred  [A] owner [C] service general [O] belligerent [S] bad\n",
      "\n",
      "gold  [A] food [C] food quality [O] good [S] great\n",
      "pred  [A] food general [C] food quality [O] good [S] great\n",
      "\n",
      "gold  [A] meal [C] food quality [O] delicious [S] great [SSEP] [A] place [C] restaurant general [O] great [S] great\n",
      "pred  [A] place [C] restaurant general [O] great [S] great [SSEP] [A] meal [C] food quality [O] delicious [S] great\n",
      "\n",
      "number of gold spans: 916, predicted spans: 993, hit: 286\n",
      "acos_rest16_0shot_test precision: 28.80 recall: 31.22 F1 = 29.96\n"
     ]
    }
   ],
   "source": [
    "labels_counts = Counter([len(l.split('[SSEP]')) for l in outputs])\n",
    "print(\"pred labels count\", labels_counts)\n",
    "\n",
    "scores, all_labels, all_preds = compute_scores(outputs,\n",
    "                                               targets,\n",
    "                                               verbose=True)\n",
    "test_type = f'{args.task}_{args.dataset}_{args.prompt_type}_{args.eval_data_split}'\n",
    "exp_results = \"{} precision: {:.2f} recall: {:.2f} F1 = {:.2f}\".format(\n",
    "                    test_type, scores['precision'], scores['recall'], scores['f1'])\n",
    "print(exp_results)\n",
    "\n",
    "log_file_path = os.path.join(f'{args.path}/outputs/{args.model}/', \"result.txt\")\n",
    "\n",
    "# compute the performance scores\n",
    "with open(log_file_path, \"a+\") as f:\n",
    "    f.write(exp_results)\n",
    "    f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e869de5-a5fe-47ce-a285-716377bc3f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpo",
   "language": "python",
   "name": "dpo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
